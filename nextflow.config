#! /usr/bin/env nextflow

// covid_analysis - NextFlow configuration script

params {
	// These 3 variables should be passed in through the command line for each plate so you don't have to edit the config with each one.
		// plate = ""
		// fastqs = "./"
		// meta = "./"

	// Variables that are best kept in the config:
    scheme_details = "$projectDir/scheme_details.csv"
	out = "$launchDir/output"
	// we have our kraken db as a softlink to another location
	kraken_db = "$projectDir/human_kraken_db"

    // Edit if more source labs added (leave as empty string )
	// If reportMap is an empty string (''), we'll write out one file for samples from each source lab and one combined report file
	// reportMap = ''
	// // If reportMap is an empty python dict ('{}'), only the report file will be produced
	// reportMap = '{}'
	// // If reportMap is a filled python dict ('{}'), we'll write out one file for samples from each dict key and one combined report file
	// This is a python dictionary mapping the NAME that will appear in the report name (Sequencing-report-NAME.csv) to:
		// the SOURCE_LAB(s) to include and (default: same as NAME)
		// a string that must be in the sample names (default: None)
	// If supplying a config, all source labs that need an individual report must be listed. Use an empty dict if accepting the defaults.
	// notice how lines must end with '\' if spanning multiple lines with text
	reportMap = "\
    {'Mecklenburg':{\
        'source_lab':'Starmed|StarMed',\
        'limit_to':'MCPH'\
        },\
    'StarMed':{\
        'source_lab':'Starmed|StarMed'\
        },\
    'Campus':{},\
    'Mission':{}\
    }"
}

// source for below code: https://github.com/CFSAN-Biostatistics/C-WAP/blob/main/nextflow.config

process {
	shell = ['/bin/bash','-e']
	//clusterOptions = '-x n141,n147,n225,n227,n228'
}

// This block needs to be modified to customise for the available computational resources
profiles {
	local_only {
		process.executor = 'local'
	}

	standard {
		executor {
			name = 'slurm'
			queueSize = 400
			// queueStatInterval = '30 sec'
		}

		process {		
			executor = 'slurm'
			// queue = <partition name here>
			time = '1 h'
			cpus = 2
			memory = '8 GB'
			
			withLabel: high_cpu {
				cpus = 20
			}
		}
	}
	
	aws {
		executor {
			name = 'slurm'
			queueSize = 400
		}
			
		process {
			time = '1 h'
			cpus = 2
			memory = '8 GB'
			
			withLabel: high_cpu {
				cpus = 15
			}
			
			withLabel: high_IO {
				// Execute only a few at a time.
				// This reduces storage IO by avoiding concurrent read access.
				maxForks = 2
			}
		}
	}
	
}

conda {
    enabled = true
// 	cacheDir = "$projectDir/conda"
// 	createOptions = '-c bioconda -c conda-forge -c defaults'
// 	conda.createTimeout = '3 h'
}
